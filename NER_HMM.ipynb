{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the cleaned data\n",
    "\n",
    "data = pd.read_csv(\"ebay_cleaned.csv\")\n",
    "\n",
    "## lowering the Token column\n",
    "data[\"Token_Lower\"] = data[\"Token\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Clean_Token</th>\n",
       "      <th>Simple_Tag</th>\n",
       "      <th>Token_Lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>Supreme</td>\n",
       "      <td>Modell</td>\n",
       "      <td>supreme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>supreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Marke</td>\n",
       "      <td>nike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>SB</td>\n",
       "      <td>Produktlinie</td>\n",
       "      <td>sb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>Dunk</td>\n",
       "      <td>Produktlinie</td>\n",
       "      <td>dunk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>High</td>\n",
       "      <td>Schuhschaft-Typ</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>By</td>\n",
       "      <td>Modell</td>\n",
       "      <td>by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>any</td>\n",
       "      <td>Modell</td>\n",
       "      <td>any</td>\n",
       "      <td>NaN</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>Means</td>\n",
       "      <td>Modell</td>\n",
       "      <td>means</td>\n",
       "      <td>NaN</td>\n",
       "      <td>means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>Red</td>\n",
       "      <td>Farbe</td>\n",
       "      <td>color_token</td>\n",
       "      <td>Farbe</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Supreme Nike SB Dunk High By any Means Red US1...</td>\n",
       "      <td>US10</td>\n",
       "      <td>US-Schuhgröße</td>\n",
       "      <td>size_token</td>\n",
       "      <td>us_size</td>\n",
       "      <td>us10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record Number                                              Title    Token  \\\n",
       "0              1  Supreme Nike SB Dunk High By any Means Red US1...  Supreme   \n",
       "1              1  Supreme Nike SB Dunk High By any Means Red US1...     Nike   \n",
       "2              1  Supreme Nike SB Dunk High By any Means Red US1...       SB   \n",
       "3              1  Supreme Nike SB Dunk High By any Means Red US1...     Dunk   \n",
       "4              1  Supreme Nike SB Dunk High By any Means Red US1...     High   \n",
       "5              1  Supreme Nike SB Dunk High By any Means Red US1...       By   \n",
       "6              1  Supreme Nike SB Dunk High By any Means Red US1...      any   \n",
       "7              1  Supreme Nike SB Dunk High By any Means Red US1...    Means   \n",
       "8              1  Supreme Nike SB Dunk High By any Means Red US1...      Red   \n",
       "9              1  Supreme Nike SB Dunk High By any Means Red US1...     US10   \n",
       "\n",
       "               Tag  Clean_Token Simple_Tag Token_Lower  \n",
       "0           Modell      supreme        NaN     supreme  \n",
       "1            Marke         nike        NaN        nike  \n",
       "2     Produktlinie           sb        NaN          sb  \n",
       "3     Produktlinie         dunk        NaN        dunk  \n",
       "4  Schuhschaft-Typ         high        NaN        high  \n",
       "5           Modell           by        NaN          by  \n",
       "6           Modell          any        NaN         any  \n",
       "7           Modell        means        NaN       means  \n",
       "8            Farbe  color_token      Farbe         red  \n",
       "9    US-Schuhgröße   size_token    us_size        us10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_count(data):\n",
    "    \"\"\"\n",
    "    Function to create a dictionary with tags as keys and the count as values\n",
    "    \"\"\"\n",
    "    flatten_data = list(data[\"Tag\"])\n",
    "    tag_counts = {}\n",
    "\n",
    "    for i in flatten_data:\n",
    "        if i in tag_counts:\n",
    "            tag_counts[i] += 1\n",
    "        else:\n",
    "            tag_counts[i] = 1\n",
    "\n",
    "    tag_counts = {key: value for key, value in sorted(tag_counts.items())}\n",
    "    return tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we will be taking the first tag of every record number which is 4286 (loss of rows from data cleaning)\n",
    "\n",
    "\n",
    "def inital_state(data):\n",
    "    \"\"\"\n",
    "    Initial State Distribution matrix for prbability of a POS tag in the starting of a sentence\n",
    "    \"\"\"\n",
    "    # data_subset = data.drop_duplicates([\"Record Number\"], ignore_index=True)\n",
    "    initial_token = list(data[\"Tag\"])\n",
    "    initial_tag = {}\n",
    "    for i in initial_token:\n",
    "        if i in initial_tag:\n",
    "            initial_tag[i] += 1\n",
    "        else:\n",
    "            initial_tag[i] = 1\n",
    "\n",
    "    for key in initial_tag:\n",
    "        initial_tag[key] = initial_tag[key] / len(initial_token)\n",
    "\n",
    "    sorted_dict = {key: value for key, value in sorted(initial_tag.items())}\n",
    "\n",
    "    pi = np.array(list(sorted_dict.values()))\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(data):\n",
    "    \"\"\"\n",
    "    This function creates transtion matrix (POS tag, POS tag)\n",
    "    and has alpha value as 1 for smoothing\n",
    "    \"\"\"\n",
    "    flatten_data = list(data[\"Tag\"])\n",
    "    transition_counts = {}\n",
    "\n",
    "    for i in range(len(flatten_data) - 1):\n",
    "        transition = (flatten_data[i], flatten_data[i + 1])\n",
    "\n",
    "        # If the transition exists in the dictionary, increment its count\n",
    "        if transition in transition_counts:\n",
    "            transition_counts[transition] += 1\n",
    "        else:\n",
    "            # If the transition is not in the dictionary, add it with a count of 1\n",
    "            transition_counts[transition] = 1\n",
    "\n",
    "    tag_list_ordered = list(tag_count(data).keys())\n",
    "\n",
    "    # 2D Matrix A with size as length of unique POS tags\n",
    "    A = np.zeros((len(tag_list_ordered), len(tag_list_ordered)), dtype=float)\n",
    "\n",
    "    for i in range(len(tag_list_ordered)):\n",
    "        for j in range(len(tag_list_ordered)):\n",
    "            count = 0\n",
    "\n",
    "            key = (tag_list_ordered[i], tag_list_ordered[j])\n",
    "\n",
    "            if key in transition_counts:\n",
    "                count = transition_counts[key]\n",
    "\n",
    "            A[i, j] = count\n",
    "\n",
    "    A = A + 1\n",
    "\n",
    "    A = A / A.sum(axis=1)[:, None]\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_matrix(data):\n",
    "    \"\"\"\n",
    "    This function is for observation matrix (Vocab,POS tag)\n",
    "    It creates a list with of vocabulary and adding \"OOV\"\n",
    "    The alpha value is 1 for smoothing\n",
    "    \"\"\"\n",
    "    flatten_data = list(zip(list(data[\"Token_Lower\"]), list(data[\"Tag\"])))\n",
    "    vocab = []\n",
    "    for i in flatten_data:\n",
    "        vocab.append(i[0])\n",
    "\n",
    "    unique_set = set(vocab)\n",
    "    unique_set.add(\"OOV\")\n",
    "\n",
    "    unique_list = list(unique_set)\n",
    "\n",
    "    vocab = {}\n",
    "    for i, word in enumerate(unique_list):\n",
    "        vocab[word] = i\n",
    "\n",
    "    emission_counts = {}\n",
    "    for i in range(len(flatten_data)):\n",
    "        if flatten_data[i] in emission_counts:\n",
    "            # If the item exists in the dictionary, increment its count\n",
    "            emission_counts[flatten_data[i]] += 1\n",
    "        else:\n",
    "            # If the item is not in the dictionary, add it with a count of 1\n",
    "            emission_counts[flatten_data[i]] = 1\n",
    "\n",
    "    tag_list_ordered = list(tag_count(data).keys())\n",
    "\n",
    "    B = np.zeros((len(tag_count(data)), len(unique_list)), dtype=float)\n",
    "\n",
    "    for i in range(len(tag_count(data))):\n",
    "        for j in range(len(unique_list)):\n",
    "            count = 0\n",
    "\n",
    "            key = (unique_list[j], tag_list_ordered[i])\n",
    "            if key in emission_counts:\n",
    "                count = emission_counts[key]\n",
    "\n",
    "            B[i, j] = count\n",
    "\n",
    "    B = B + 1\n",
    "\n",
    "    B = B / B.sum(axis=1)[:, None]\n",
    "    return B, unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(\n",
    "    obs,\n",
    "    pi,\n",
    "    A,\n",
    "    B,\n",
    "):\n",
    "    \"\"\"Infer most likely state sequence using the Viterbi algorithm.\n",
    "\n",
    "    Args:\n",
    "        obs: An iterable of ints representing observations.\n",
    "        pi: A 1D numpy array of floats representing initial state probabilities.\n",
    "        A: A 2D numpy array of floats representing state transition probabilities.\n",
    "        B: A 2D numpy array of floats representing emission probabilities.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of:\n",
    "        * A 1D numpy array of ints representing the most likely state sequence.\n",
    "        * A float representing the probability of the most likely state sequence.\n",
    "    \"\"\"\n",
    "    N = len(obs)\n",
    "    Q, V = B.shape  # num_states, num_observations\n",
    "\n",
    "    # d_{ti} = max prob of being in state i at step t\n",
    "    #   AKA viterbi\n",
    "    # \\psi_{ti} = most likely state preceeding state i at step t\n",
    "    #   AKA backpointer\n",
    "\n",
    "    # initialization\n",
    "    log_d = [np.log(pi) + np.log(B[:, obs[0]])]\n",
    "    log_psi = [np.zeros((Q,))]\n",
    "\n",
    "    # recursion\n",
    "    for z in obs[1:]:\n",
    "        log_da = np.expand_dims(log_d[-1], axis=1) + np.log(A)\n",
    "        log_d.append(np.max(log_da, axis=0) + np.log(B[:, z]))\n",
    "        log_psi.append(np.argmax(log_da, axis=0))\n",
    "\n",
    "    # termination\n",
    "    log_ps = np.max(log_d[-1])\n",
    "    qs = [-1] * N\n",
    "    qs[-1] = int(np.argmax(log_d[-1]))\n",
    "    for i in range(N - 2, -1, -1):\n",
    "        qs[i] = log_psi[i + 1][qs[i + 1]]\n",
    "\n",
    "    return qs, np.exp(log_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using the training data to test the accuracy and sent_id is the record number\n",
    "def test(sent_id, data):\n",
    "    test_data = data.loc[data[\"Record Number\"] == sent_id]\n",
    "\n",
    "    # test = [tup for sent in test_data for tup in sent]\n",
    "    test_words = list(test_data[\"Token\"])\n",
    "    test_tags = list(test_data[\"Tag\"])\n",
    "\n",
    "    obs = []\n",
    "    vocab = emission_matrix(data)[1]\n",
    "    for i in range(len(test_words)):\n",
    "        if test_words[i] in vocab:\n",
    "            obs.append(vocab.index(test_words[i]))\n",
    "        else:\n",
    "            obs.append(vocab.index(\"OOV\"))\n",
    "\n",
    "    return obs, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, sent_id, seq):\n",
    "    tags_test = test(sent_id, data)[1]\n",
    "    obs_model = []\n",
    "    tag_order = list(tag_count(data).keys())\n",
    "    for i in seq:\n",
    "        obs_model.append(tag_order[i])\n",
    "\n",
    "    score = []\n",
    "    print(\"\\n\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Testing for Sentence Id : \" + str(sent_id))\n",
    "    print(\"\\n\")\n",
    "    for i in range(len(obs_model)):\n",
    "        print(f\"True: {tags_test[i]} | Predicted: {obs_model[i]}\")\n",
    "        if tags_test[i] == obs_model[i]:\n",
    "            score.append(1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "\n",
    "    accuracy_num = round(sum(score) / len(score) * 100, 3)\n",
    "    print(\"The Accuracy of the model for this case is : \" + str(accuracy_num) + \"%\")\n",
    "\n",
    "    return accuracy_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order of sequence in which POS tag is used :\n",
      "['Abteilung', 'Aktivität', 'Akzente', 'Anlass', 'Besonderheiten', 'Charakter', 'Charakter Familie', 'Dämpfungsgrad', 'EU-Schuhgröße', 'Erscheinungsjahr', 'Farbe', 'Futtermaterial', 'Gewebeart', 'Herstellernummer', 'Herstellungsland und -region', 'Innensohlenmaterial', 'Jahreszeit', 'Laufsohlenmaterial', 'Marke', 'Maßeinheit', 'Modell', 'Muster', 'No Tag', 'Obermaterial', 'Obscure', 'Produktart', 'Produktlinie', 'Schuhschaft-Typ', 'Schuhweite', 'Stil', 'Stollentyp', 'Thema', 'UK-Schuhgröße', 'US-Schuhgröße', 'Verschluss', 'Zwischensohlen-Typ']\n",
      "The Initial State distribution is \n",
      "[6.84580528e-02 1.22601957e-02 2.15982721e-03 1.24295939e-02\n",
      " 7.72879346e-03 4.44670309e-04 2.11747766e-04 6.77592851e-04\n",
      " 4.84902384e-02 1.50340914e-03 7.93842375e-02 2.11747766e-04\n",
      " 3.68441113e-03 4.95489773e-02 1.16461271e-03 4.65845085e-04\n",
      " 8.46991064e-04 3.17621649e-04 9.72980985e-02 9.95214500e-04\n",
      " 1.30584847e-01 1.60928302e-03 1.81891331e-01 1.54152374e-02\n",
      " 2.13865244e-03 1.07800788e-01 6.46465930e-02 1.42717994e-02\n",
      " 5.29369415e-04 6.08774827e-02 4.23495532e-05 3.72676068e-03\n",
      " 7.85584212e-03 1.07779613e-02 7.74996824e-03 1.79985601e-03]\n",
      "The Transition Matrix is\n",
      "[[0.07861731 0.02171918 0.00214133 ... 0.00091771 0.00734169 0.00091771]\n",
      " [0.02764228 0.13821138 0.00162602 ... 0.00162602 0.01138211 0.00162602]\n",
      " [0.06521739 0.01449275 0.11594203 ... 0.01449275 0.02898551 0.00724638]\n",
      " ...\n",
      " [0.02568807 0.00183486 0.00183486 ... 0.41284404 0.00183486 0.00183486]\n",
      " [0.04228856 0.02985075 0.00995025 ... 0.00248756 0.1840796  0.01243781]\n",
      " [0.03305785 0.00826446 0.00826446 ... 0.00826446 0.00826446 0.28099174]]\n",
      "The Observation Matrix is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.33881210e-05 9.33881210e-05 9.33881210e-05 ... 9.33881210e-05\n",
      "  9.33881210e-05 9.33881210e-05]\n",
      " [1.24161907e-04 1.24161907e-04 1.24161907e-04 ... 1.24161907e-04\n",
      "  1.24161907e-04 1.24161907e-04]\n",
      " [1.31978356e-04 1.31978356e-04 1.31978356e-04 ... 1.31978356e-04\n",
      "  1.31978356e-04 1.31978356e-04]\n",
      " ...\n",
      " [1.25250501e-04 1.25250501e-04 1.25250501e-04 ... 1.25250501e-04\n",
      "  1.25250501e-04 1.25250501e-04]\n",
      " [1.27534753e-04 1.27534753e-04 1.27534753e-04 ... 1.27534753e-04\n",
      "  1.27534753e-04 1.27534753e-04]\n",
      " [1.32275132e-04 1.32275132e-04 1.32275132e-04 ... 1.32275132e-04\n",
      "  1.32275132e-04 1.32275132e-04]]\n"
     ]
    }
   ],
   "source": [
    "def store_values(value_list, value):\n",
    "    value_list.append(value)\n",
    "\n",
    "\n",
    "pi = inital_state(data)\n",
    "print(\"The order of sequence in which POS tag is used :\")\n",
    "print(list(tag_count(data).keys()))\n",
    "\n",
    "print(\"The Initial State distribution is \")\n",
    "print(pi)\n",
    "\n",
    "A = transition_matrix(data)\n",
    "print(\"The Transition Matrix is\")\n",
    "print(transition_matrix(data))\n",
    "\n",
    "B = emission_matrix(data)[0]\n",
    "print(\"The Observation Matrix is\")\n",
    "print(emission_matrix(data)[0])\n",
    "\n",
    "# Id for test sentences\n",
    "test_sent_id = [*range(3000, 3003, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Testing for Sentence Id : 3000\n",
      "\n",
      "\n",
      "True: No Tag | Predicted: No Tag\n",
      "True: No Tag | Predicted: No Tag\n",
      "True: Abteilung | Predicted: No Tag\n",
      "True: Marke | Predicted: No Tag\n",
      "True: No Tag | Predicted: No Tag\n",
      "True: No Tag | Predicted: No Tag\n",
      "The Accuracy of the model for this case is : 66.667%\n",
      "The Model probability for this case is : 1.9400980390753678e-24\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Testing for Sentence Id : 3001\n",
      "\n",
      "\n",
      "True: Marke | Predicted: Modell\n",
      "True: Produktlinie | Predicted: Modell\n",
      "True: Produktlinie | Predicted: Modell\n",
      "True: Modell | Predicted: Modell\n",
      "True: Modell | Predicted: Modell\n",
      "True: Schuhschaft-Typ | Predicted: Modell\n",
      "True: Abteilung | Predicted: Modell\n",
      "True: Obermaterial | Predicted: Modell\n",
      "True: Farbe | Predicted: Farbe\n",
      "True: Farbe | Predicted: Farbe\n",
      "True: US-Schuhgröße | Predicted: Farbe\n",
      "True: EU-Schuhgröße | Predicted: Farbe\n",
      "The Accuracy of the model for this case is : 33.333%\n",
      "The Model probability for this case is : 5.462215679685256e-51\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Testing for Sentence Id : 3002\n",
      "\n",
      "\n",
      "True: Marke | Predicted: Modell\n",
      "True: Produktlinie | Predicted: Modell\n",
      "True: Produktlinie | Predicted: Modell\n",
      "True: Modell | Predicted: Modell\n",
      "True: Muster | Predicted: Modell\n",
      "True: Akzente | Predicted: Modell\n",
      "True: Abteilung | Predicted: Modell\n",
      "True: No Tag | Predicted: No Tag\n",
      "True: EU-Schuhgröße | Predicted: EU-Schuhgröße\n",
      "True: No Tag | Predicted: No Tag\n",
      "True: No Tag | Predicted: No Tag\n",
      "True: No Tag | Predicted: No Tag\n",
      "True: Herstellernummer | Predicted: No Tag\n",
      "The Accuracy of the model for this case is : 46.154%\n",
      "The Model probability for this case is : 5.96397952992216e-52\n",
      "----------------------------------------------------------------\n",
      "The Average Model Accuracy is 48.718%\n"
     ]
    }
   ],
   "source": [
    "# Testing for 3 sentences\n",
    "stored_values = []\n",
    "stored_loss = []\n",
    "for i in test_sent_id:\n",
    "    obs = test(i, data)[0]\n",
    "    seq, model_prob = viterbi(obs, pi, A, B)\n",
    "    model_accuracy = accuracy(data, i, seq)\n",
    "    store_values(stored_values, model_accuracy)\n",
    "    print(\"The Model probability for this case is : \" + str(model_prob))\n",
    "\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\n",
    "    \"The Average Model Accuracy is \"\n",
    "    + str(round(sum(stored_values) / len(stored_values), 3))\n",
    "    + \"%\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
